{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTsEYdtov6tp"
   },
   "source": [
    "# Beijing Air Quality Forecasting Starter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml_env (Python 3.10.13)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
    "\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(\"C:\\\\Users\\\\Merveille\\\\.kaggle\", exist_ok=True)\n",
    "\n",
    "# Write kaggle.json file\n",
    "with open(\"C:\\\\Users\\\\Merveille\\\\.kaggle\\\\kaggle.json\", \"w\") as f:\n",
    "    f.write('{\"username\":\"merveillekangabire\",\"key\":\"12573b5c7b1a50c1ad03b1d4923ba262\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-slugify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = r\"C:\\Users\\Merveille\\notebooks\\assignment-1-time-series-forecasting-may-2025.zip\"\n",
    "extract_to = r\"C:\\Users\\Merveille\\notebooks\\assignment-1\"\n",
    "\n",
    "# Create the destination folder if it doesn't exist\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "print(\"âœ… Unzipped successfully to:\", extract_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWkSHhqXrCqF"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, GRU, Bidirectional\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_C4HV99rHd5",
    "outputId": "e8b4a359-23e7-4e5a-84e9-e4d3a4d54e94"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to access datasets\n",
    "test_path = r'C:\\Users\\Merveille\\notebooks\\assignment-1\\test.csv'\n",
    "train_path = r'C:\\Users\\Merveille\\notebooks\\assignment-1\\train.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxW-6b_jrLAL"
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "# Ensure train.csv and test.csv are saved in your Google Drive in the same folder.\n",
    "# Replace the file paths below with the actual paths to your dataset.\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "train.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRse3uqRrft5"
   },
   "source": [
    "# Explore the training data\n",
    "\n",
    "In this sections explore your dataset with appropiate statistics and visualisations to understand your better. Ensure that you explain output of every code cell and what it entails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "3R74CEBFrYok",
    "outputId": "0e593627-9c80-490c-826e-74e4df4a2249"
   },
   "outputs": [],
   "source": [
    "# Inspecting the first few rows of the dataset to understand its structure.\n",
    "print(\"Training Data Overview:\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-om6hH_RtG8Z",
    "outputId": "8fefc873-d80f-4b45-ead2-89bbfc8d4d62"
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35IGrMYRscQx"
   },
   "outputs": [],
   "source": [
    "# Ensure 'datetime' column is in datetime format\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "# Set the 'datetime' column as the index for better time-series handling\n",
    "train.set_index('datetime', inplace=True)\n",
    "# val.set_index('datetime', inplace=True)\n",
    "test.set_index('datetime', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABAqt0Jztd5s"
   },
   "source": [
    "# Handle missing values\n",
    "\n",
    "\n",
    "- Check the dataset for missing values and decide how to handle them.\n",
    "- In this example, missing values are filled with the mean. You can experiment with other strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2n29Ge1tami"
   },
   "outputs": [],
   "source": [
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKndkdRuty1C"
   },
   "source": [
    "# Separate features and target\n",
    "\n",
    "- Feel free to trop any non-essential columns like that you think might not contribute to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QETLRAo_tvQH"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['pm2.5', 'No'], axis=1)\n",
    "y_train = train['pm2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyP2mDjruG9R"
   },
   "outputs": [],
   "source": [
    "# Reshape data for LSTM input\n",
    "# LSTM models require data in the shape (samples, timesteps, features).\n",
    "# Here, the data is reshaped to add a \"timesteps\" dimension.\n",
    "X_train = np.expand_dims(X_train, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d488782wuR2W"
   },
   "source": [
    "# Build model\n",
    "\n",
    "Below is a simple LSTM model. Your task is to experiment with different parameters like, numbers of layers, units, activation functions, and optimizers, etc to get the best performing model. Experiment with other optimizers (e.g., SGD) or hyperparameters to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d488782wuR2W"
   },
   "source": [
    "# model1\n",
    "\n",
    "Using LSTM, Relu, and dropout of 0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "mfx2LPHxq5fG",
    "outputId": "a5eab018-edc3-4ca5-f5f9-e896e2cbd0a1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Dropout\n",
    "# define model\n",
    "model = Sequential([\n",
    "    LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=[lambda y, y_pred: tf.sqrt(tf.reduce_mean(tf.square(y - y_pred)))]  # RMSE metric\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uM0Xuq7XvdTZ",
    "outputId": "b6df9dee-acfd-416b-d50e-ab9b40201c73"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# You can adjust the number of epochs and batch size to improve performance.\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "NKxlO7SmxFpU",
    "outputId": "5bd92101-7840-44f2-eda6-2bf10a1680f3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def evaluate_and_plot_on_train_only(model, history, X_train, y_train, scaler_y=None, model_name='Model'):\n",
    "    # Predict on training data\n",
    "    predictions = model.predict(X_train)\n",
    "    \n",
    "    # Compute training RMSE\n",
    "    rmse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    # Rescale if a scaler was used\n",
    "    if scaler_y:\n",
    "        predictions_rescaled = scaler_y.inverse_transform(predictions)\n",
    "        y_train_rescaled = scaler_y.inverse_transform(y_train)\n",
    "    else:\n",
    "        predictions_rescaled = predictions\n",
    "        y_train_rescaled = y_train\n",
    "\n",
    "    # Plot: Actual vs Predicted\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(y_train_rescaled, label='Actual')\n",
    "    plt.plot(predictions_rescaled, label='Predicted')\n",
    "    plt.title(f'{model_name} - Predictions vs Actuals\\nRMSE: {rmse:.4f}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Target')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot: Training loss per epoch\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.axhline(y=mean_squared_error(y_train, predictions), color='blue', linestyle='--', label='Final Train MSE')\n",
    "    plt.title(f'{model_name} - Training Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"[{model_name}] Final Training RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot_on_train_only(\n",
    "    model, history, X_train, y_train,\n",
    "    scaler_y=None,\n",
    "    model_name='Bidirectional LSTM'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d488782wuR2W"
   },
   "source": [
    "# model2\n",
    "\n",
    "This model uses a mixture of GRU and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    GRU(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=[lambda y, y_pred: tf.sqrt(tf.reduce_mean(tf.square(y - y_pred)))]  # RMSE metric\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot_on_train_only(\n",
    "    model2, history, X_train, y_train,\n",
    "    scaler_y=None,\n",
    "    model_name='GRU'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d488782wuR2W"
   },
   "source": [
    "# model3\n",
    "\n",
    "This model uses a mixture of GRU and  bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    Bidirectional(LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
    "    Dropout(0.2),\n",
    "    GRU(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model3.compile(\n",
    "    optimizer=Adam(learning_rate=0.007),\n",
    "    loss='mse',\n",
    "    metrics=[lambda y, y_pred: tf.sqrt(tf.reduce_mean(tf.square(y - y_pred)))]  # RMSE metric\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model3.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot_on_train_only(\n",
    "    model3, history, X_train, y_train,\n",
    "    scaler_y=None,\n",
    "    model_name='Bidirectional'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d488782wuR2W"
   },
   "source": [
    "# model4\n",
    "\n",
    "This model uses a mixture of GRU and Bidirectional LSTM, with change in compiler and learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential([\n",
    "    Bidirectional(LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
    "    Dropout(0.2),\n",
    "    GRU(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model4.compile(\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=[lambda y, y_pred: tf.sqrt(tf.reduce_mean(tf.square(y - y_pred)))]  # RMSE metric\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model4.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot_on_train_only(\n",
    "    model4, history, X_train, y_train,\n",
    "    scaler_y=None,\n",
    "    model_name='Bidirectional'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d488782wuR2W"
   },
   "source": [
    "# model5\n",
    "\n",
    "This model uses a mixture of LSTM and Bidirectional LSTM, with change in compiler and learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential([\n",
    "    LSTM(128, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model5.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='mse',\n",
    "    metrics=[lambda y, y_pred: tf.sqrt(tf.reduce_mean(tf.square(y - y_pred)))]  # RMSE metric\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model5.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot_on_train_only(\n",
    "    model5, history, X_train, y_train,\n",
    "    scaler_y=None,\n",
    "    model_name='LSTM'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential([\n",
    "    Bidirectional(LSTM(80, activation='tanh', return_sequences=True, dropout=0.25, recurrent_dropout=0.15)),\n",
    "    Bidirectional(LSTM(40, activation='tanh', return_sequences=False, dropout=0.25, recurrent_dropout=0.15)),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.15),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model6.compile(\n",
    "    optimizer=Adam(learning_rate=0.0007),\n",
    "    loss='mse',\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model6.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot_on_train_only(\n",
    "    model5, history, X_train, y_train,\n",
    "    scaler_y=None,\n",
    "    model_name='LSTM'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nrw_e7OVwe6R",
    "outputId": "9a7966e6-fccf-409e-b3e4-c6ba968d610e"
   },
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "os.makedirs(r\"C:\\Users\\Merveille\\notebooks\\assignment-1\\data\", exist_ok=True)\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = test.drop(['No'], axis=1)\n",
    "X_test = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "# Make predictions on the test set using the trained model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Clean predictions\n",
    "predictions = np.nan_to_num(predictions)\n",
    "predictions = np.round(predictions).astype(int)\n",
    "\n",
    "# Make sure number of predictions matches number of row IDs\n",
    "assert len(predictions.flatten()) == len(sample_submission), \"Mismatch between prediction count and row IDs\"\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'row ID': test.index.strftime('%Y-%m-%d') + ' ' + test.index.hour.astype(str) + ':' + test.index.strftime('%M:%S'),\n",
    "    'pm2.5': predictions.flatten()\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_path = r\"C:\\Users\\Merveille\\notebooks\\assignment-1\\data\\first_submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "# Submit to Kaggle\n",
    "!kaggle competitions submit -c assignment-1-time-series-forecasting-may-2025 -f \"C:/Users/Merveille/notebooks/assignment-1/data/first_submission.csv\" -m \"Test Submitted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
